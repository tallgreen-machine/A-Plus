"""
V2 Training API Router

Provides REST endpoints for the V2 training system:
- POST /api/v2/training/start - Start training job
- GET /api/v2/training/jobs - List training jobs
- GET /api/v2/training/jobs/{job_id} - Get job status
- GET /api/v2/training/jobs/{job_id}/results - Get job results
- DELETE /api/v2/training/jobs/{job_id} - Cancel job

Integrates with training/ components for ML-powered parameter optimization.
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone
import asyncio
import uuid
import logging
import traceback
import json

# RQ imports
from redis import Redis
from rq import Queue
from rq.job import Job

from training.data_collector import DataCollector
from training.backtest_engine import BacktestEngine
from training.strategies.liquidity_sweep import LiquiditySweepStrategy
from training.optimizers.grid_search import GridSearchOptimizer
from training.optimizers.random_search import RandomSearchOptimizer
from training.optimizers.bayesian import BayesianOptimizer, is_bayesian_available
from training.validator import WalkForwardValidator
from training.configuration_writer import ConfigurationWriter
from training.progress_tracker import ProgressTracker

# Database imports
import asyncpg
import os
from configparser import ConfigParser

log = logging.getLogger(__name__)
router = APIRouter(prefix="/api/v2/training", tags=["Training V2"])


# ===== RQ Configuration =====

def get_redis_url() -> str:
    """Get Redis connection URL from environment."""
    return os.getenv('REDIS_URL', 'redis://localhost:6379/0')


def get_redis_connection() -> Redis:
    """Get Redis connection for RQ."""
    redis_url = get_redis_url()
    return Redis.from_url(redis_url)


def get_training_queue() -> Queue:
    """Get RQ queue for training jobs."""
    redis_conn = get_redis_connection()
    return Queue('training', connection=redis_conn)

# ===== Request/Response Models =====

class StartTrainingRequest(BaseModel):
    """Request body for starting a training job."""
    strategy: str = Field(..., description="Strategy name (e.g., LIQUIDITY_SWEEP)")
    symbol: str = Field(..., description="Trading pair (e.g., BTC/USDT)")
    exchange: str = Field(..., description="Exchange name (e.g., binance)")
    timeframe: str = Field(..., description="Timeframe (e.g., 5m, 1h)")
    regime: str = Field(default="sideways", description="Market regime: bull, bear, or sideways")
    optimizer: str = Field(
        default="bayesian",
        description="Optimizer: grid, random, or bayesian"
    )
    lookback_days: int = Field(default=90, description="Days of historical data")
    n_iterations: Optional[int] = Field(
        default=200,
        description="Iterations for random/bayesian optimizer"
    )
    run_validation: bool = Field(
        default=True,
        description="Run walk-forward validation"
    )
    
    class Config:
        schema_extra = {
            "example": {
                "strategy": "LIQUIDITY_SWEEP",
                "symbol": "BTC/USDT",
                "exchange": "binance",
                "timeframe": "5m",
                "regime": "sideways",
                "optimizer": "bayesian",
                "lookback_days": 90,
                "n_iterations": 200,
                "run_validation": True
            }
        }


class TrainingJobResponse(BaseModel):
    """Response for training job."""
    job_id: str
    status: str
    strategy: str
    symbol: str
    exchange: str
    timeframe: str
    optimizer: str
    progress_pct: float
    current_episode: Optional[int]
    total_episodes: Optional[int]
    created_at: datetime
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    duration_seconds: Optional[int]
    error_message: Optional[str]


class TrainingResultsResponse(BaseModel):
    """Response for training job results."""
    job_id: str
    status: str
    config_id: Optional[str]
    best_score: Optional[float]
    best_parameters: Optional[Dict[str, Any]]
    best_metrics: Optional[Dict[str, Any]]
    validation_summary: Optional[Dict[str, Any]]


# ===== Database Helper =====

def get_db_url() -> str:
    """Get database URL from config."""
    # Try DATABASE_URL first (standard)
    db_url = os.getenv('DATABASE_URL')
    if db_url:
        return db_url
    
    # Try individual DB_* environment variables (trad.env format)
    db_host = os.getenv('DB_HOST')
    if db_host:
        return (
            f"postgresql://{os.getenv('DB_USER', 'traduser')}:"
            f"{os.getenv('DB_PASSWORD', '')}@"
            f"{db_host}:"
            f"{os.getenv('DB_PORT', '5432')}/"
            f"{os.getenv('DB_NAME', 'trad')}"
        )
    
    # Fallback to config.ini
    config = ConfigParser()
    config.read('config.ini')
    
    if 'database' in config:
        db_config = config['database']
        return (
            f"postgresql://{db_config.get('user', 'traduser')}:"
            f"{db_config.get('password', '')}@"
            f"{db_config.get('host', 'localhost')}:"
            f"{db_config.get('port', '5432')}/"
            f"{db_config.get('database', 'traddb')}"
        )
    
    return "postgresql://traduser:tradpass@localhost:5432/traddb"


# ===== Background Training Task =====

async def run_training_task(
    job_id: str,
    request: StartTrainingRequest
):
    """
    Run training job in background.
    
    Updates database with progress and results.
    """
    db_url = get_db_url()
    progress = ProgressTracker(job_id=job_id, db_url=db_url)
    
    try:
        # Update status to RUNNING
        conn = await asyncpg.connect(db_url)
        await conn.execute(
            """
            UPDATE training_jobs 
            SET status = 'RUNNING', started_at = $1, progress_pct = 0
            WHERE job_id = $2
            """,
            datetime.utcnow(),
            job_id
        )
        await conn.close()
        
        log.info(f"Training job {job_id} started: {request.strategy} {request.symbol}")
        
        # ===== Step 1: Data Preparation =====
        await progress.start('data_preparation', {
            'symbol': request.symbol,
            'exchange': request.exchange,
            'timeframe': request.timeframe,
            'lookback_days': request.lookback_days
        })
        
        log.info(f"[{job_id}] Step 1/4: Preparing data...")
        collector = DataCollector(db_url=db_url)
        data = await collector.fetch_ohlcv(
            symbol=request.symbol,
            exchange=request.exchange,
            timeframe=request.timeframe,
            lookback_days=request.lookback_days
        )
        
        await progress.update(
            step_percentage=100.0,
            step_details={'candles': len(data)}
        )
        
        # ===== Step 2: Optimization =====
        await progress.start('optimization', {
            'optimizer': request.optimizer,
            'n_iterations': request.n_iterations
        })
        
        log.info(f"[{job_id}] Step 2/4: Defining parameter space...")
        
        # Map strategy name to class
        strategy_map = {
            'LIQUIDITY_SWEEP': LiquiditySweepStrategy
        }
        
        strategy_class = strategy_map.get(request.strategy)
        if not strategy_class:
            raise ValueError(f"Unknown strategy: {request.strategy}")
        
        temp_strategy = strategy_class({})
        parameter_space = temp_strategy.get_parameter_space()
        
        log.info(f"[{job_id}] Running {request.optimizer} optimization...")
        
        engine = BacktestEngine(
            initial_capital=10000,
            fee_rate=0.001,
            slippage_rate=0.0005
        )
        
        # Progress callback for optimizer
        best_score_so_far = float('-inf')
        best_params_so_far = None
        
        async def optimizer_callback(iteration: int, total: int, score: float, params: Dict[str, Any]):
            nonlocal best_score_so_far, best_params_so_far
            if score > best_score_so_far:
                best_score_so_far = score
                best_params_so_far = params
            
            step_pct = (iteration / total) * 100
            await progress.update(
                step_percentage=step_pct,
                iteration=iteration,
                total_iterations=total,
                best_score=best_score_so_far,
                current_score=score,
                best_params=best_params_so_far
            )
        
        # Select optimizer
        if request.optimizer == 'grid':
            optimizer = GridSearchOptimizer(verbose=False)
            opt_result = optimizer.optimize(
                backtest_engine=engine,
                data=data,
                strategy_class=strategy_class,
                parameter_space=parameter_space,
                objective='sharpe_ratio',
                min_trades=10
            )
        elif request.optimizer == 'random':
            optimizer = RandomSearchOptimizer(seed=42, verbose=False)
            opt_result = optimizer.optimize(
                backtest_engine=engine,
                data=data,
                strategy_class=strategy_class,
                parameter_space=parameter_space,
                n_iterations=request.n_iterations,
                objective='sharpe_ratio',
                min_trades=10
            )
        elif request.optimizer == 'bayesian':
            if not is_bayesian_available():
                raise ValueError("Bayesian optimizer not available. Install scikit-optimize.")
            optimizer = BayesianOptimizer(random_state=42, verbose=False)
            opt_result = optimizer.optimize(
                backtest_engine=engine,
                data=data,
                strategy_class=strategy_class,
                parameter_space=parameter_space,
                n_calls=request.n_iterations,
                n_initial_points=max(10, request.n_iterations // 10),
                objective='sharpe_ratio',
                min_trades=10
            )
        else:
            raise ValueError(f"Unknown optimizer: {request.optimizer}")
        
        await progress.update(step_percentage=100.0)
        
        # ===== Step 3: Validation (Optional) =====
        validation_result = None
        
        if request.run_validation:
            await progress.start('validation', {
                'train_window_days': 60,
                'test_window_days': 30,
                'gap_days': 7
            })
            
            log.info(f"[{job_id}] Step 3/4: Walk-forward validation...")
            
            validator = WalkForwardValidator(
                train_window_days=60,
                test_window_days=30,
                gap_days=7
            )
            
            validation_result = validator.validate(
                config=opt_result['best_parameters'],
                data=data,
                strategy_class=strategy_class,
                backtest_engine=engine
            )
            
            await progress.update(step_percentage=100.0)
        
        # ===== Step 4: Save Configuration =====
        await progress.start('save_config', {
            'config_destination': 'trained_configurations'
        })
        
        log.info(f"[{job_id}] Step 4/4: Saving configuration...")
        
        # Re-run backtest with best params for full metrics
        final_strategy = strategy_class(opt_result['best_parameters'])
        final_result = engine.run_backtest(data=data, strategy_instance=final_strategy)
        
        writer = ConfigurationWriter(db_url=db_url)
        config_id = await writer.save_configuration(
            strategy=request.strategy,
            symbol=request.symbol,
            exchange=request.exchange,
            timeframe=request.timeframe,
            parameters=opt_result['best_parameters'],
            backtest_result=final_result,
            validation_result=validation_result,
            optimizer=request.optimizer,
            metadata={
                'job_id': job_id,
                'lookback_days': request.lookback_days,
                'n_iterations': request.n_iterations
            }
        )
        
        await progress.update(step_percentage=100.0)
        
        # ===== Mark training complete =====
        await progress.complete()
        
        # ===== Update Job Status: COMPLETED =====
        completed_at = datetime.utcnow()
        
        conn = await asyncpg.connect(db_url)
        
        # Get started_at to calculate duration
        row = await conn.fetchrow(
            "SELECT started_at FROM training_jobs WHERE job_id = $1",
            job_id
        )
        
        duration_seconds = None
        if row and row['started_at']:
            duration_seconds = int((completed_at - row['started_at']).total_seconds())
        
        await conn.execute(
            """
            UPDATE training_jobs 
            SET 
                status = 'COMPLETED',
                progress_pct = 100,
                completed_at = $1,
                duration_seconds = $2,
                best_config_id = $3,
                best_score = $4,
                best_parameters = $5,
                best_metrics = $6
            WHERE job_id = $7
            """,
            completed_at,
            duration_seconds,
            config_id,
            opt_result['best_score'],
            opt_result['best_parameters'],
            opt_result['best_metrics'],
            job_id
        )
        
        await conn.close()
        
        log.info(
            f"✅ Training job {job_id} completed: "
            f"config_id={config_id}, "
            f"best_score={opt_result['best_score']:.3f}, "
            f"duration={duration_seconds}s"
        )
        
    except Exception as e:
        log.error(f"Training job {job_id} failed: {e}", exc_info=True)
        
        # Mark progress as failed
        try:
            await progress.error(str(e))
        except:
            pass
        
        # Update status to FAILED
        try:
            conn = await asyncpg.connect(db_url)
            await conn.execute(
                """
                UPDATE training_jobs 
                SET 
                    status = 'FAILED',
                    completed_at = $1,
                    error_message = $2,
                    error_trace = $3
                WHERE job_id = $4
                """,
                datetime.utcnow(),
                str(e),
                traceback.format_exc(),
                job_id
            )
            await conn.close()
        except Exception as db_error:
            log.error(f"Failed to update job status: {db_error}")


# ===== API Endpoints =====

@router.post("/start", response_model=TrainingJobResponse)
async def start_training(request: StartTrainingRequest):
    """
    Start a new training job.
    
    The job is enqueued in Redis and processed by the training worker.
    Use the returned job_id to poll for status and results.
    
    Example:
        ```
        POST /api/v2/training/start
        {
            "strategy": "LIQUIDITY_SWEEP",
            "symbol": "BTC/USDT",
            "exchange": "binance",
            "timeframe": "5m",
            "optimizer": "bayesian",
            "lookback_days": 90,
            "n_iterations": 200,
            "run_validation": true
        }
        ```
    
    Returns:
        TrainingJobResponse with job_id and initial status
    """
    try:
        # Generate job ID
        job_id = str(uuid.uuid4())
        
        # Insert job record
        db_url = get_db_url()
        conn = await asyncpg.connect(db_url)
        
        await conn.execute(
            """
            INSERT INTO training_jobs (
                job_id,
                strategy,
                symbol,
                exchange,
                timeframe,
                optimizer,
                lookback_days,
                n_iterations,
                parameter_space,
                status,
                created_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, 'PENDING', $10)
            """,
            job_id,
            request.strategy,
            request.symbol,
            request.exchange,
            request.timeframe,
            request.optimizer,
            request.lookback_days,
            request.n_iterations,
            json.dumps({}),  # parameter_space as JSON string
            datetime.now()  # Use naive datetime for timestamp without time zone
        )
        
        await conn.close()
        
        # Enqueue job in RQ (replaces BackgroundTasks)
        from training.rq_jobs import run_training_job
        
        queue = get_training_queue()
        rq_job = queue.enqueue(
            run_training_job,
            args=(                     # Explicit args tuple for RQ serialization
                job_id,
                request.strategy,
                request.symbol,
                request.exchange,
                request.timeframe,
                request.regime,
                request.optimizer,
                request.lookback_days,
                request.n_iterations,
                request.run_validation
            ),
            job_timeout=1800,          # RQ parameter: 30 minutes in seconds (RQ 2.x requires integer)
            result_ttl=86400,          # RQ parameter: keep result for 24 hours
            failure_ttl=604800         # RQ parameter: keep failed jobs for 7 days
        )
        
        log.info(f"Training job {job_id} enqueued in RQ: {request.strategy} {request.symbol} (RQ job: {rq_job.id})")
        
        return TrainingJobResponse(
            job_id=job_id,
            status="PENDING",
            strategy=request.strategy,
            symbol=request.symbol,
            exchange=request.exchange,
            timeframe=request.timeframe,
            optimizer=request.optimizer,
            progress_pct=0,
            current_episode=None,
            total_episodes=request.n_iterations,
            created_at=datetime.utcnow(),
            started_at=None,
            completed_at=None,
            duration_seconds=None,
            error_message=None
        )
        
    except Exception as e:
        log.error(f"Failed to start training job: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/jobs", response_model=List[TrainingJobResponse])
async def list_training_jobs(
    status: Optional[str] = None,
    strategy: Optional[str] = None,
    limit: int = 50
):
    """
    List training jobs with optional filters.
    
    Query Parameters:
        - status: Filter by status (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)
        - strategy: Filter by strategy name
        - limit: Maximum number of jobs to return (default: 50)
    
    Returns:
        List of TrainingJobResponse
    """
    try:
        db_url = get_db_url()
        conn = await asyncpg.connect(db_url)
        
        # Build query
        query = "SELECT * FROM training_jobs WHERE 1=1"
        params = []
        param_idx = 1
        
        if status:
            query += f" AND status = ${param_idx}"
            params.append(status)
            param_idx += 1
        
        if strategy:
            query += f" AND strategy = ${param_idx}"
            params.append(strategy)
            param_idx += 1
        
        query += f" ORDER BY created_at DESC LIMIT ${param_idx}"
        params.append(limit)
        
        rows = await conn.fetch(query, *params)
        await conn.close()
        
        jobs = []
        for row in rows:
            jobs.append(TrainingJobResponse(
                job_id=row['job_id'],
                status=row['status'],
                strategy=row['strategy'],
                symbol=row['symbol'],
                exchange=row['exchange'],
                timeframe=row['timeframe'],
                optimizer=row['optimizer'],
                progress_pct=float(row['progress_pct'] or 0),
                current_episode=row['current_episode'],
                total_episodes=row['total_episodes'],
                created_at=row['created_at'],
                started_at=row['started_at'],
                completed_at=row['completed_at'],
                duration_seconds=row['duration_seconds'],
                error_message=row['error_message']
            ))
        
        return jobs
        
    except Exception as e:
        log.error(f"Failed to list jobs: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/jobs/{job_id}", response_model=TrainingJobResponse)
async def get_training_job(job_id: str):
    """
    Get training job status.
    
    Returns:
        TrainingJobResponse with current job status and progress
    """
    try:
        db_url = get_db_url()
        conn = await asyncpg.connect(db_url)
        
        row = await conn.fetchrow(
            "SELECT * FROM training_jobs WHERE job_id = $1",
            job_id
        )
        
        await conn.close()
        
        if not row:
            raise HTTPException(status_code=404, detail=f"Job {job_id} not found")
        
        return TrainingJobResponse(
            job_id=row['job_id'],
            status=row['status'],
            strategy=row['strategy'],
            symbol=row['symbol'],
            exchange=row['exchange'],
            timeframe=row['timeframe'],
            optimizer=row['optimizer'],
            progress_pct=float(row['progress_pct'] or 0),
            current_episode=row['current_episode'],
            total_episodes=row['total_episodes'],
            created_at=row['created_at'],
            started_at=row['started_at'],
            completed_at=row['completed_at'],
            duration_seconds=row['duration_seconds'],
            error_message=row['error_message']
        )
        
    except HTTPException:
        raise
    except Exception as e:
        log.error(f"Failed to get job: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/jobs/{job_id}/results", response_model=TrainingResultsResponse)
async def get_training_results(job_id: str):
    """
    Get training job results.
    
    Only available after job is COMPLETED.
    
    Returns:
        TrainingResultsResponse with best configuration and metrics
    """
    try:
        db_url = get_db_url()
        conn = await asyncpg.connect(db_url)
        
        row = await conn.fetchrow(
            "SELECT * FROM training_jobs WHERE job_id = $1",
            job_id
        )
        
        await conn.close()
        
        if not row:
            raise HTTPException(status_code=404, detail=f"Job {job_id} not found")
        
        if row['status'] != 'COMPLETED':
            raise HTTPException(
                status_code=400,
                detail=f"Job {job_id} not completed (status: {row['status']})"
            )
        
        return TrainingResultsResponse(
            job_id=row['job_id'],
            status=row['status'],
            config_id=row['best_config_id'],
            best_score=float(row['best_score']) if row['best_score'] else None,
            best_parameters=row['best_parameters'],
            best_metrics=row['best_metrics'],
            validation_summary=None  # TODO: Add validation summary if needed
        )
        
    except HTTPException:
        raise
    except Exception as e:
        log.error(f"Failed to get results: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/jobs/{job_id}")
async def cancel_training_job(job_id: str):
    """
    Cancel a training job.
    
    Only works for PENDING or RUNNING jobs.
    
    Returns:
        Success message
    """
    try:
        db_url = get_db_url()
        conn = await asyncpg.connect(db_url)
        
        row = await conn.fetchrow(
            "SELECT status FROM training_jobs WHERE job_id = $1",
            job_id
        )
        
        if not row:
            await conn.close()
            raise HTTPException(status_code=404, detail=f"Job {job_id} not found")
        
        if row['status'] not in ['PENDING', 'RUNNING']:
            await conn.close()
            raise HTTPException(
                status_code=400,
                detail=f"Cannot cancel job with status {row['status']}"
            )
        
        # Update status to CANCELLED
        await conn.execute(
            """
            UPDATE training_jobs 
            SET status = 'CANCELLED', completed_at = $1
            WHERE job_id = $2
            """,
            datetime.utcnow(),
            job_id
        )
        
        await conn.close()
        
        log.info(f"Training job {job_id} cancelled")
        
        return {"message": f"Job {job_id} cancelled successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        log.error(f"Failed to cancel job: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/jobs/{job_id}/progress")
async def get_training_progress(job_id: str):
    """
    Get real-time training progress for a job.
    
    Returns:
        - percentage: Overall progress (0-100)
        - current_step: Current workflow step name
        - step_number: Current step number (1-4)
        - step_percentage: Progress within current step (0-100)
        - estimated_completion: ETA timestamp (if available)
        - current_iteration: Current optimizer iteration (if in optimization)
        - total_iterations: Total optimizer iterations
        - best_score: Best score found so far
        - current_score: Score of current iteration
        - best_params: Best parameters found so far
        - is_complete: Whether training is finished
        - error_message: Error message (if failed)
    
    Example response:
        {
            "job_id": "abc123",
            "percentage": 62.5,
            "current_step": "Optimization",
            "step_number": 2,
            "total_steps": 4,
            "step_percentage": 75.0,
            "current_iteration": 38,
            "total_iterations": 50,
            "best_score": 1.85,
            "current_score": 1.42,
            "best_params": {"pierce_depth": 0.15, ...},
            "estimated_completion": "2025-10-23T06:15:30Z",
            "is_complete": false,
            "started_at": "2025-10-23T06:00:00Z",
            "updated_at": "2025-10-23T06:10:25Z"
        }
    """
    try:
        db_url = get_db_url()
        conn = await asyncpg.connect(db_url)
        
        # Get latest progress record
        row = await conn.fetchrow(
            """
            SELECT 
                job_id,
                percentage,
                current_step,
                step_number,
                total_steps,
                step_percentage,
                step_details,
                started_at,
                updated_at,
                estimated_completion,
                current_iteration,
                total_iterations,
                best_score,
                current_score,
                best_params,
                is_complete,
                error_message
            FROM training_progress
            WHERE job_id = $1
            ORDER BY updated_at DESC
            LIMIT 1
            """,
            job_id
        )
        
        await conn.close()
        
        if not row:
            # No progress yet - check if job exists
            conn = await asyncpg.connect(db_url)
            job_row = await conn.fetchrow(
                "SELECT status, created_at FROM training_jobs WHERE job_id = $1",
                job_id
            )
            await conn.close()
            
            if not job_row:
                raise HTTPException(status_code=404, detail=f"Job {job_id} not found")
            
            # Job exists but no progress yet
            return {
                "job_id": job_id,
                "percentage": 0.0,
                "current_step": "Pending",
                "step_number": 0,
                "total_steps": 4,
                "step_percentage": 0.0,
                "is_complete": False,
                "started_at": job_row['created_at'].isoformat() if job_row['created_at'] else None,
                "updated_at": job_row['created_at'].isoformat() if job_row['created_at'] else None
            }
        
        # Build response
        response = {
            "job_id": row['job_id'],
            "percentage": float(row['percentage']) if row['percentage'] else 0.0,
            "current_step": row['current_step'],
            "step_number": row['step_number'],
            "total_steps": row['total_steps'],
            "step_percentage": float(row['step_percentage']) if row['step_percentage'] else 0.0,
            "step_details": row['step_details'],
            "started_at": row['started_at'].isoformat() if row['started_at'] else None,
            "updated_at": row['updated_at'].isoformat() if row['updated_at'] else None,
            "estimated_completion": row['estimated_completion'].isoformat() if row['estimated_completion'] else None,
            "current_iteration": row['current_iteration'],
            "total_iterations": row['total_iterations'],
            "best_score": float(row['best_score']) if row['best_score'] else None,
            "current_score": float(row['current_score']) if row['current_score'] else None,
            "best_params": row['best_params'],
            "is_complete": row['is_complete'],
            "error_message": row['error_message']
        }
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        log.error(f"Failed to get progress: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
